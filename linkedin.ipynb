{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTML,HTMLSession\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pygsheets\n",
    "import logging\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from google.oauth2.service_account import Credentials\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "scopes = ['https://www.googleapis.com/auth/spreadsheets',\n",
    "          'https://www.googleapis.com/auth/drive']\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = \"googledrive/searchconsole-364317-ee5fb100ebef.json\"\n",
    "credentials = Credentials.from_service_account_file(gc, scopes=scopes)\n",
    "gc1 = gspread.authorize(credentials)\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "# open a google sheet\n",
    "gs = gc1.open('WebResults')\n",
    "def write_df(df,gs,sheet_index):\n",
    "    try:\n",
    "        wks = gs.get_worksheet(sheet_index)\n",
    "        # check if there are existing data and shape\n",
    "        existing_data = get_existing_jobs(wks)\n",
    "        if len(existing_data) != 0:\n",
    "            df_values = df.values.tolist()\n",
    "            gs.values_append('joblisting', {'valueInputOption': 'RAW'}, {'values': df_values})\n",
    "        else:\n",
    "            wks.set_dataframe(df,f'A1')\n",
    "            set_with_dataframe(worksheet=wks, dataframe=df, include_index=False,include_column_header=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def get_existing_jobs(gs,sheet_index):\n",
    "    try:\n",
    "        wks = gs.get_worksheet(sheet_index)\n",
    "        available = [i for i in wks.col_values(4) if i != \"job_id\"]\n",
    "        return available\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "files = get_existing_jobs(gs,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting application details\n",
      "'NoneType' object has no attribute 'find'\n",
      "local variable 'jobid' referenced before assignment\n",
      "Getting application details\n",
      "Getting application details\n",
      "'NoneType' object has no attribute 'find'\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "local variable 'jobid' referenced before assignment\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "local variable 'jobid' referenced before assignment\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n",
      "Getting application details\n"
     ]
    }
   ],
   "source": [
    "class LinkedInScrap:\n",
    "    def __init__(self,existing_jobs):\n",
    "        self.existing_jobs = existing_jobs\n",
    "    \n",
    "    def check_exising_jobs(self,jobid):\n",
    "        if jobid in self.existing_jobs:\n",
    "            raise Exception(f\"Job with ID '{jobid}' already exists,skipping...\")\n",
    "\n",
    "    @staticmethod\n",
    "    def cleanupcriteria(df_json):\n",
    "        result = {}\n",
    "        for d in df_json:\n",
    "            result.update(d)\n",
    "        return result\n",
    "    def external_link(self, job_link):\n",
    "        \"\"\"this function will return the external link if the job has been posted.\n",
    "\n",
    "\n",
    "        Args:\n",
    "            job_link (string): link to job to be scrapped.\n",
    "\n",
    "        Returns:\n",
    "            _type_: exact link redirect\n",
    "        \"\"\"\n",
    "        resp = requests.get(job_link)\n",
    "        soup = bs(resp.text, \"html.parser\")\n",
    "        apply_btn_link = (\n",
    "            soup.find(class_=\"sign-up-modal__direct-apply-on-company-site\")\n",
    "            .find(\"a\")\n",
    "            .get(\"href\")\n",
    "        )\n",
    "        apply_btn_link = requests.get(apply_btn_link).url\n",
    "        return apply_btn_link\n",
    "\n",
    "    def searchlinkedinjobs(self, start=0):\n",
    "        \"\"\"this function will return the search result linkedin job search\n",
    "\n",
    "\n",
    "        Args:\n",
    "            start (int, optional): . Defaults to 0.\n",
    "\n",
    "        Returns:\n",
    "            response:\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"keywords\": \"medical services jobs\",\n",
    "            \"location\": \"Kenya\",\n",
    "            # \"geoId\": \"100710459\",\n",
    "            # \"trk\": \"public_jobs_jobs-search-bar_search-submit\",\n",
    "            \"start\": start,\n",
    "        }\n",
    "        response = requests.get(\n",
    "            \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search\",\n",
    "            params=params,\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def jobdetails_info(self, job_api_details):\n",
    "        \n",
    "        resp = requests.get(job_api_details)\n",
    "        jobdesc = bs(resp.text, \"html.parser\")\n",
    "        job_desc_details = jobdesc.find(\n",
    "            class_=\"show-more-less-html__markup show-more-less-html__markup--clamp-after-5\"\n",
    "        )\n",
    "        job_desc_details = str(job_desc_details).replace('show-more-less-html__markup show-more-less-html__markup--clamp-after-5','job-desc')\n",
    "        jobcriterialist = [\n",
    "            {\n",
    "                i.find(class_=\"description__job-criteria-subheader\")\n",
    "                .text.strip(): i.find(class_=\"description__job-criteria-subheader\")\n",
    "                .find_next_sibling()\n",
    "                .text.strip()\n",
    "            }\n",
    "            for i in jobdesc.find(\n",
    "                \"ul\", class_=\"description__job-criteria-list\"\n",
    "            ).find_all(\"li\")\n",
    "        ]\n",
    "        jobcriterialist = LinkedInScrap.cleanupcriteria(jobcriterialist)\n",
    "\n",
    "        out = {\"jobcriterialist\": jobcriterialist, \"job_desc_details\": job_desc_details}\n",
    "        return out\n",
    "\n",
    "    def jobdetails(self, listings):\n",
    "        try:\n",
    "            job_title = listings.find(class_=\"base-search-card__title\").text.strip()\n",
    "            company = listings.find(class_=\"base-search-card__subtitle\").text.strip()\n",
    "            # location     = listings.find(class_ = 'job-search-card__location').text.strip()\n",
    "            job_link = listings.find(class_=\"base-card__full-link\")\n",
    "            if job_link:\n",
    "                job_link = job_link.get(\"href\")\n",
    "                jobid = job_link.split(\"?\")[0].split(\"-\")[-1]\n",
    "                self.check_exising_jobs(jobid)\n",
    "            \n",
    "                job_api_details = (\n",
    "                    f\"https://ke.linkedin.com/jobs-guest/jobs/api/jobPosting/{jobid}\"\n",
    "                )\n",
    "                # get link to application\n",
    "                print(\"Getting application details\")\n",
    "                application_link = self.external_link(job_link)\n",
    "                logger.debug(\"Getting Job details\")\n",
    "                details = self.jobdetails_info(job_api_details)\n",
    "            company_link = listings.find(class_=\"hidden-nested-link\")\n",
    "            if company_link:\n",
    "                company_link = company_link.get(\"href\")\n",
    "            company_logo = (\n",
    "                listings.find(\"div\", class_=\"search-entity-media\")\n",
    "                .find(\"img\")\n",
    "                .get(\"data-delayed-url\")\n",
    "            )\n",
    "            location = listings.find(class_=\"job-search-card__location\").text.strip()\n",
    "            posting_time = listings.time.get(\"datetime\")\n",
    "            res = {\n",
    "                \"job_title\": job_title,\n",
    "                \"company\": company,\n",
    "                \"job_link\": job_link,\n",
    "                \"job_id\": jobid,\n",
    "                \"application_link\": application_link,\n",
    "                \"job_api_details\": job_api_details,\n",
    "                \"company_logo\": company_logo,\n",
    "                \"location\": location,\n",
    "                \"posting_time\": posting_time,\n",
    "                \"crawl_time\": str(datetime.datetime.now()),\n",
    "                # \"url\": response.url,\n",
    "                \"details\": details,\n",
    "            }\n",
    "            \n",
    "            return res\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def post_data(self,res):\n",
    "        try:\n",
    "            post_data = {\n",
    "                'companylogo'      :  res['company_logo'], \n",
    "                'companyname'      :  res['company'] ,\n",
    "                'location'         :  res['location'] ,\n",
    "                'postingdate'      :  res['posting_date'] ,\n",
    "                'job_desc'         :  f\"\"\"{res['details']}\"\"\",\n",
    "                'applicationlinks' :  res['application_link'] \n",
    "            }\n",
    "            return post_data\n",
    "        except Exception as e:\n",
    "            return None\n",
    "        \n",
    "    def main(self,end):\n",
    "        start = 0\n",
    "        jd = []\n",
    "        while True:\n",
    "            logger.debug(\"getting links\")\n",
    "            response = self.searchlinkedinjobs(start)\n",
    "            soup = bs(response.text, 'html.parser').find_all(\"li\")\n",
    "            logger.debug(\"Parsing getting links\")\n",
    "            for i in range(len(soup)):\n",
    "                logger.debug(f'{i} of {len(soup)}')\n",
    "                \n",
    "                new_jd = self.jobdetails(soup[i])\n",
    "                jd.append(new_jd)\n",
    "            start = start + 25\n",
    "            logger.debug('current start', start,end = \"\\r\")\n",
    "            if start >= end:\n",
    "                break  \n",
    "        return jd \n",
    "\n",
    "init = LinkedInScrap(existing_jobs=files)\n",
    "jd = init.main(end=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hospitals and Health Care                                                      9\n",
       "Government Administration                                                      8\n",
       "Wellness and Fitness Services                                                  4\n",
       "Financial Services                                                             3\n",
       "Banking and Financial Services                                                 2\n",
       "Non-profit Organization Management                                             2\n",
       "Software Development                                                           2\n",
       "Research Services, Biotechnology Research, and Pharmaceutical Manufacturing    1\n",
       "Travel Arrangements                                                            1\n",
       "Personal Care Product Manufacturing and Manufacturing                          1\n",
       "Medical Equipment Manufacturing, Oil and Gas, and Hospitals and Health Care    1\n",
       "International Affairs                                                          1\n",
       "Biotechnology Research and Pharmaceutical Manufacturing                        1\n",
       "Name: details.jobcriterialist.Industries, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(list(filter(None,jd)))['details.jobcriterialist.Industries'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Manegarial', 'ict']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def cleanupindustry(label):\n",
    "    if re.search(\"Hospitals|Health|Care\", label.lower()):\n",
    "        label = \"Hospitalsandhealthcare\"\n",
    "    elif re.search(\"government \", label.lower()):\n",
    "        label = \"government\"\n",
    "    elif re.search(\"business|finance|banking \", label.lower()):\n",
    "        label = \"business\"\n",
    "    elif re.search(\"non-profit|non-government|ngo|private\", label.lower()):\n",
    "        label = \"ngo\"\n",
    "    elif re.search(\"computer|technology|software\", label.lower()):\n",
    "        label = \"ict\"\n",
    "    else:\n",
    "        label = \"Other\"\n",
    "    \n",
    "    return label\n",
    "\n",
    "\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manegarial', 'ict']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "def cleanuplabel(label):\n",
    "    label = label.lower()\n",
    "    categories = {\n",
    "        \"sales|sale|marketing\": \"sales&marketing\",\n",
    "        \"management\": \"manegarial\",\n",
    "        \"engineering\": \"engineering\",\n",
    "        \"ict|information|technology\": \"ict\",\n",
    "        \"human resources|human|resources\": \"human resources\",\n",
    "        \"purchasing and supply chain|purchasing|supply\": \"purchasing & supply chain\",\n",
    "        \"finance|banking|account\": \"finance&accounting\",\n",
    "        \"administrative|admin|administrator\": \"administrative\",\n",
    "        \"consult\": \"consulting\",\n",
    "        \"research\": \"research\",\n",
    "        \"analyst\": \"analyst\",\n",
    "        \"business|development\": \"business development\",\n",
    "        \"data\": \"datascience\",\n",
    "        \"education|training\": \"education\",\n",
    "        \"design|creative\": \"graphicdesign\",\n",
    "        \"health|care|provider|doctor|hospital\": \"medical&healthcare\",\n",
    "        \"building|appliances|electrical|electronics|manufacturing\": \"building&construction\"\n",
    "    }\n",
    "    for pattern, category in categories.items():\n",
    "        if re.search(pattern, label):\n",
    "            return category\n",
    "    return \"Other\"\n",
    "list(map(lambda x: x if len(x) > 0 else ['Other'],set([i for i in list(map(cleanuplabel,\"Other, Information Technology, and Management\".split(\" \")+[\"Other, Information Technology, and Management\"])) if i != \"Other\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Other'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = \"Other, Information Technology, and Management\".split(\", \")\n",
    "# result = ['Other' if len(label) == 0 else label for label in set(cleanuplabel(label) for label in \"Other, Information Technology, and Management\".split(\", \")) if label != 'Other']\n",
    "list(filter(None,jd))[0]['details']['jobcriterialist']['Job function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from google.oauth2.service_account import Credentials\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "class DriveTools:\n",
    "    scopes = ['https://www.googleapis.com/auth/spreadsheets',\n",
    "              'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "    def __init__(self, creds_file, workbook):\n",
    "        self.creds_file = creds_file\n",
    "        self.gauth = GoogleAuth()\n",
    "        credentials = Credentials.from_service_account_file(self.creds_file, scopes=self.scopes)\n",
    "        self.gc1 = gspread.authorize(credentials)\n",
    "        self.gs = self.gc1.open(workbook)\n",
    "        \n",
    "       \n",
    "    def get_existing_jobs(self, sheet_index):\n",
    "        try:\n",
    "            wks = self.gs.get_worksheet(sheet_index)\n",
    "            available = [i for i in wks.col_values(4) if i != \"job_id\"]\n",
    "            return available\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def write_df(self, df, sheet_index):\n",
    "        try:\n",
    "            wks = self.gs.get_worksheet(sheet_index)\n",
    "            # check if there are existing data and shape\n",
    "            existing_data = self.get_existing_jobs(sheet_index)\n",
    "            if len(existing_data) != 0:\n",
    "                df_values = df.values.tolist()\n",
    "                self.gs.values_append('joblisting', {'valueInputOption': 'RAW'}, {'values': df_values})\n",
    "            else:\n",
    "                # set_with_dataframe(wks,df, 'A1',include_index=False,)\n",
    "                set_with_dataframe(worksheet=wks, dataframe=df, include_index=False,include_column_header=True, resize=True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "     \n",
    "gd = DriveTools(credsfile,workbook=\"WebResults\")\n",
    "# gd.write_df(df.head(1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googledrive.drivetools import DriveTools\n",
    "from jobsites.linkedin import LinkedInScrap\n",
    "from blogspot.postingengine import *\n",
    "\n",
    "\n",
    "credsfile = \"googledrive/searchconsole-364317-ee5fb100ebef.json\"\n",
    "gd = DriveTools(credsfile, workbook=\"WebResults\")\n",
    "existing_jobs = gd.get_existing_jobs(2)\n",
    "jobs = LinkedInScrap(existing_jobs)\n",
    "joblisting = jobs.main(end=2)\n",
    "top50 = list(filter(None, joblisting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50[0][\"details\"][\"jobcriterialist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ = post_body(\n",
    "    company_logo=top50[0][\"company_logo\"],\n",
    "    company=top50[0][\"company\"],\n",
    "    location=top50[0][\"location\"],\n",
    "    posting_time=top50[0][\"posting_time\"],\n",
    "    details=top50[0]['details']['job_desc_details'],\n",
    "    application_link=top50[0][\"application_link\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cdd2b1d8a903540a382ffdacd23b871908285f1e74077ccb749d19a5c9c7084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
